{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Adding Context to Word Frequency Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the raw data from word frequency counts is compelling, it does little but describe quantitative features of the corpus. In order to determine if the statistics are indicative of a trend in word usage we must add value to the word frequencies. In this exercise we will produce a ratio of the occurences of `privacy` to the number of words in the entire corpus. Then we will compare the occurences of `privacy` to the indivudal number of transcripts within the corpus. This data will allow us identify trends that are worthy of further investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 1: Determining a ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add context to our word frequency counts, we can work with the corpus in a number of different ways. One of the easiest is to compare the number of words in the entire corpus to the frequency of the word we are investigating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by calling on all the <span style=\"cursor:help;\" title=\"a set of instructions that performs a specific task\"><b>functions</b></span> we will need. Remember that the first few sentences are calling on pre-installed <i>Python</i> <span style=\"cursor:help;\" title=\"packages of functions and code that serve specific purposes\"><b>modules</b></span>, and anything with a `def` at the beginning is a custom function built specifically for these exercises. The text in red describes the purpose of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is where the modules are imported\n",
    "\n",
    "from os import listdir\n",
    "from os.path import splitext\n",
    "from os.path import basename\n",
    "\n",
    "# These functions iterate through the directory and create a list of filenames\n",
    "\n",
    "def list_textfiles(directory):\n",
    "    \"Return a list of filenames ending in '.txt'\"\n",
    "    textfiles = []\n",
    "    for filename in listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            textfiles.append(directory + \"/\" + filename)\n",
    "    return textfiles\n",
    "\n",
    "\n",
    "def remove_ext(filename):\n",
    "    \"Removes the file extension, such as .txt\"\n",
    "    name, extension = splitext(filename)\n",
    "    return name\n",
    "\n",
    "\n",
    "def remove_dir(filepath):\n",
    "    \"Removes the path from the file name\"\n",
    "    name = basename(filepath)\n",
    "    return name\n",
    "\n",
    "\n",
    "def get_filename(filepath):\n",
    "    \"Removes the path and file extension from the file name\"\n",
    "    filename = remove_ext(filepath)\n",
    "    name = remove_dir(filename)\n",
    "    return name\n",
    "\n",
    "# These functions work on the content of the files\n",
    "\n",
    "def read_file(filename):\n",
    "    \"Read the contents of FILENAME and return as a string.\"\n",
    "    infile = open(filename)\n",
    "    contents = infile.read()\n",
    "    infile.close()\n",
    "    return contents\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"Renders all text lowercase and removes punctuation\"\n",
    "    lower_text = text.lower()\n",
    "    punctuation = '!@#$%^&*()_-+={}[]:;\"\\'|<>,.?/~`'\n",
    "    clean_text = \"\"\n",
    "    for character in lower_text:\n",
    "        if character not in punctuation:\n",
    "            clean_text += character\n",
    "    return clean_text\n",
    "\n",
    "\n",
    "def count_in_list(item_to_count, list_to_search):\n",
    "    \"Counts the number of a specified word within a list of words\"\n",
    "    number_of_hits = 0\n",
    "    for item in list_to_search:\n",
    "        if item == item_to_count:\n",
    "            number_of_hits += 1\n",
    "    return number_of_hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next piece of code we will cycle through our directory again: first assigning readable names to our files and storing them as a list in the variable `filenames`; then we will remove the case and punctuation from the text, split the words into a list of tokens, and assign the words in each file to a list in the variable `corpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for files in list_textfiles('data2'):\n",
    "    files = get_filename(files)\n",
    "    filenames.append(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for filename in list_textfiles('data2'):\n",
    "    text = read_file(filename)\n",
    "    clean = clean_text(text)\n",
    "    words = clean.split()\n",
    "    corpus.append(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we recreate our list from the last exercise, counting the instances of the word `privacy` in each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances of the word 'privacy' in 2006 : 409\n",
      "Instances of the word 'privacy' in 2007 : 298\n",
      "Instances of the word 'privacy' in 2008 : 273\n",
      "Instances of the word 'privacy' in 2009 : 679\n",
      "Instances of the word 'privacy' in 2010 : 672\n",
      "Instances of the word 'privacy' in 2011 : 750\n",
      "Instances of the word 'privacy' in 2012 : 667\n",
      "Instances of the word 'privacy' in 2013 : 1100\n",
      "Instances of the word 'privacy' in 2014 : 1805\n"
     ]
    }
   ],
   "source": [
    "for words, names in zip(corpus, filenames):\n",
    "    print\"Instances of the word \\'privacy\\' in\",names, \":\", count_in_list(\"privacy\", words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use the `len` function to count the total number of words in each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5998460 words in 2006\n",
      "There are 6943608 words in 2007\n",
      "There are 5582923 words in 2008\n",
      "There are 7826514 words in 2009\n",
      "There are 7252848 words in 2010\n",
      "There are 6217244 words in 2011\n",
      "There are 8301652 words in 2012\n",
      "There are 7180541 words in 2013\n",
      "There are 8199435 words in 2014\n"
     ]
    }
   ],
   "source": [
    "for files, names in zip(corpus, filenames):\n",
    "    print\"There are\", len(files), \"words in\", names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the ratio of the word `privacy` to the total number of words in the file. To accomplish this we simply divide the two numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of instances of privacy to total number of words in the corpus:\n",
      "0.000068 : 2006\n",
      "0.000043 : 2007\n",
      "0.000049 : 2008\n",
      "0.000087 : 2009\n",
      "0.000093 : 2010\n",
      "0.000121 : 2011\n",
      "0.000080 : 2012\n",
      "0.000153 : 2013\n",
      "0.000220 : 2014\n"
     ]
    }
   ],
   "source": [
    "print(\"Ratio of instances of privacy to total number of words in the corpus:\")\n",
    "for words, names in zip(corpus, filenames):\n",
    "    print '{:.6f}'.format(float(count_in_list(\"privacy\", words))/(float(len(words)))),\":\",names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our descriptive statistics concerning word frequencies have added value. We can see that there has indeed been a steady increase in the frequency of the use of the word `privacy` in our corpus. When we investigate the yearly usage, we can see that the frequency almost doubled between 2008 and 2009, as well as dramatic increase between 2012 and 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part 2: Counting the number of transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way we can provide context is to process the corpus in a different way. Instead of splitting the data by word, we will split it in larger chunks pertaining to each individual transcript. Each transcript corresponds to a unique debate but starts with exactly the same formatting, making the files easy to split. The text below shows the beginning of a transcript. The first words are `OFFICIAL REPORT (HANSARD)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "OFFICIAL REPORT (HANSARD)\n",
    "  \n",
    "  \n",
    "    House of Commons Debates\n",
    "    VOLUME 141\n",
    "    NUMBER 001\n",
    "    1st SESSION\n",
    "    39th PARLIAMENT\n",
    "    Monday, April 3, 2006\n",
    "    Speaker: The Honourable Peter Milliken\n",
    "    HOUSE OF COMMONS\n",
    "    CANADA\n",
    "    (Table of Contents appears at back of this issue.)\n",
    "    COMMONS DEBATES\n",
    "    April 3, 2006\n",
    "    DEBATES\n",
    "    Edited Hansard * Table of Contents * Number 001 (Official Version)\n",
    "    Official Report * Table of Contents * Number 001 (Official Version)\n",
    "    Compte rendu officiel * Table des matieres * Numero 001 (Version officielle)\n",
    "    141\n",
    "    001\n",
    "    03\n",
    "    04\n",
    "    2006\n",
    "    2006/04/03 11:05:00\n",
    "    House of Commons\n",
    "    Debats de la Chambre des communes\n",
    "    House of Commons Debates\n",
    "    39\n",
    "    1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will pass the files to another variable, called `corpus_1`. Instead of removing capitalization and punctuation, all we will do is split the files at every occurence of `OFFICIAL REPORT (HANSARD)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_1 = []\n",
    "for filename in list_textfiles('data2'):\n",
    "    text = read_file(filename)\n",
    "    words = text.split(\" OFFICIAL REPORT (HANSARD)\")\n",
    "    corpus_1.append(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can count the number of files in each dataset. This is also an important activity for error-checking. While it is easy to trust the numerical output of the code when it works sucessfully, we must always be sure to check that the code is actually performing in exactly the way we want it to. In this case, these numbers can be cross-referenced with the original XML data, where each transcript exists as its own file. A quick check of the directory shows that the numbers are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 97 files in 2006\n",
      "There are 117 files in 2007\n",
      "There are 93 files in 2008\n",
      "There are 128 files in 2009\n",
      "There are 119 files in 2010\n",
      "There are 98 files in 2011\n",
      "There are 131 files in 2012\n",
      "There are 111 files in 2013\n",
      "There are 127 files in 2014\n"
     ]
    }
   ],
   "source": [
    "for files, names in zip(corpus_1, filenames):\n",
    "    print\"There are\", len(files), \"files in\", names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a screenshot of some of the raw data. We can see that there are <u>97</u> files in 2006, <u>117</u> in 2007 and <u>93</u> in 2008. The rest of the data is also correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"filecount.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the amount of occurences of `privacy` with the number of debates occuring in each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2006 there were 97 debates. The word privacy was uttered 409 times.\n",
      "In 2007 there were 117 debates. The word privacy was uttered 298 times.\n",
      "In 2008 there were 93 debates. The word privacy was uttered 273 times.\n",
      "In 2009 there were 128 debates. The word privacy was uttered 679 times.\n",
      "In 2010 there were 119 debates. The word privacy was uttered 672 times.\n",
      "In 2011 there were 98 debates. The word privacy was uttered 750 times.\n",
      "In 2012 there were 131 debates. The word privacy was uttered 667 times.\n",
      "In 2013 there were 111 debates. The word privacy was uttered 1100 times.\n",
      "In 2014 there were 127 debates. The word privacy was uttered 1805 times.\n"
     ]
    }
   ],
   "source": [
    "for names, files, words in zip(filenames, corpus_1, corpus):\n",
    "    print\"In\", names, \"there were\", len(files), \"debates. The word privacy was uttered\", count_in_list('privacy', words), \"times.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers confirm our earlier results. There is a clear indication that the usage of the term `privacy` is increasing, with major changes occuring between the years 2008 and 2009, as well as between 2012 and 2014. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
